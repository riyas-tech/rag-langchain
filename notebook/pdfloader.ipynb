{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179e7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8112197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 PDF files to process\n",
      "\n",
      " Processing: GenericAITest.pdf\n",
      " Loaded 3 pages\n",
      "\n",
      " Total documents loaded : 3\n"
     ]
    }
   ],
   "source": [
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all pdf files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    # Find all PDF files recursively\n",
    "\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\n Processing: {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\" Loaded {len(documents)} pages\") \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error : {e}\") \n",
    "\n",
    "        print(f\"\\n Total documents loaded : {len(all_documents)}\")    \n",
    "        return all_documents;\n",
    "\n",
    "all_pdf_documents = process_all_pdfs(\"data\\\\pdf\\\\\")      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c70f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_spliter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \",\"\"]\n",
    "    )\n",
    "    split_docs = text_spliter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    #show example of a chunks\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66af4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 3 documents into 17 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: https://crsreports.congress.gov \n",
      " \n",
      "Updated April 2, 2025\n",
      "Generative Artificial Intelligence: Overview, Issues, and \n",
      "Considerations for Congress \n",
      "Generative artificial intelligence (GenAI) refers to AI...\n",
      "Metadata: {'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}\n",
      "[Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='https://crsreports.congress.gov \\n \\nUpdated April 2, 2025\\nGenerative Artificial Intelligence: Overview, Issues, and \\nConsiderations for Congress \\nGenerative artificial intelligence (GenAI) refers to AI \\nmodels, in particular those that use machine learning (ML) \\nand are trained on large volumes of data, that are able to \\ngenerate new content. In contrast, other AI models may \\nhave a primary goal of classifying data, such as facial \\nrecognition image data, or making decisions, such as those \\nused in automated vehicles. GenAI, when prompted (often \\nby a user inputting text), can create various outputs, \\nincluding text, images, videos, computer code, or music. \\nThe public release of many GenAI tools, and the race by \\ncompanies to develop ever-more powerful AI models, have \\ngenerated widespread discussion of their capabilities, \\npotential concerns with their use, and debates about their \\ngovernance and regulation. This CRS In Focus describes'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='generated widespread discussion of their capabilities, \\npotential concerns with their use, and debates about their \\ngovernance and regulation. This CRS In Focus describes \\nthe development and uses of GenAI, concerns raised by the \\nuse of GenAI tools, and considerations for Congress.  \\nBackground \\nAI can generally be thought of as computerized systems \\nthat work and react in ways commonly considered to \\nrequire human intelligence, such as learning, solving \\nproblems, and achieving goals under uncertain and varying \\nconditions, with varying levels of autonomy. AI can \\nencompass a range of technologies, methodologies, and \\napplication areas, such as natural language processing, \\nrobotics, and facial recognition. \\nThe AI technologies underpinning many GenAI tools are \\nthe result of decades of research. For example, recurrent \\nneural networks (RNNs), a type of ML loosely modeled \\nafter the human brain that detects patterns in sequential'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='the result of decades of research. For example, recurrent \\nneural networks (RNNs), a type of ML loosely modeled \\nafter the human brain that detects patterns in sequential \\ndata, underwent much development and improvement in the \\n1980s-1990s. RNNs can generate text, but they have limited \\nability to retain contextual information across large strings \\nof words, are slow to train, and are not easily scaled up by \\nincreasing computational power or training data size. \\nMore recent technical advances—notably the introduction \\nof the Transformer architecture by Google researchers in \\n2017 and improvements in generative pre-trained \\ntransformer (GPT) models since around 2019—have \\ncontributed to dramatic improvement in GenAI \\nperformance. Transformer models process a sequence of \\nwhole sentences rather than analyzing word by word. They \\nuse mathematical techniques called attention or self-\\nattention to detect how data elements, even when far away'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='whole sentences rather than analyzing word by word. They \\nuse mathematical techniques called attention or self-\\nattention to detect how data elements, even when far away \\nsequentially, influence and depend on each other. These \\nmethods make GPT models faster to train, more efficient in \\nunderstanding context, and highly scalable.  \\nOther critical components to recent GenAI advances have \\nbeen the availability of large amounts of data and the size \\nof their language models. Large language models (LLMs) \\nare AI systems that aim to model language, sometimes \\nusing millions or billions of parameters (i.e., numbers in the \\nmodel that determine how inputs are converted to outputs). \\nRepeatedly tweaking these parameters, using mathematical \\noptimization techniques and large amounts of data and \\ncomputational power, increases model performance. \\nNotably, GenAI models work to match the style and \\nappearance of the underlying training data. They have also'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='computational power, increases model performance. \\nNotably, GenAI models work to match the style and \\nappearance of the underlying training data. They have also \\ndemonstrated emergent abilities, meaning capabilities that \\ntheir developers and users did not anticipate but that are \\nemerging as the models grow larger. \\nLLMs have been characterized as foundation models (also \\ncalled general-purpose AI), meaning models trained on \\nlarge and diverse datasets that can be adapted to a wide \\nrange of downstream tasks. As described by the Stanford \\nUniversity Institute for Human-Centered AI, foundation \\nmodels may be built on or integrated into multiple AI \\nsystems across various domains (e.g., text-based GPT \\nmodels that can perform arithmetic and computer \\nprogramming tasks, which were outside the scope of their \\noriginal training). This capability has the potential for both \\nbenefits (e.g., concentrating efforts to reduce bias and \\nimprove robustness) and drawbacks (e.g., security failures'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='original training). This capability has the potential for both \\nbenefits (e.g., concentrating efforts to reduce bias and \\nimprove robustness) and drawbacks (e.g., security failures \\nor inequities that flow to downstream applications). \\nCapabilities and Advances \\nThe increase in size of recent GenAI models (with hundreds \\nof billions or trillions of parameters) has led to improved \\ncapabilities over previous systems (with millions or a few \\nbillion parameters). According to the AI Index 2024 Annual \\nReport, “LLMs have surpassed human performance on \\ntraditional English-language benchmarks,” and the report \\nargues that the “rapid advancement has led to the need for \\nmore comprehensive benchmarks.” \\nInitial GenAI tools tended to excel at single input and \\noutput types—such as text to text for chatbots or text to \\nimage for image generators. More multimodal GenAI \\nmodels are available now, meaning they can process and \\nintegrate information from multiple types of data or'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='image for image generators. More multimodal GenAI \\nmodels are available now, meaning they can process and \\nintegrate information from multiple types of data or \\nmodalities simultaneously. For example, Google’s Gemini \\nmodels can use text-image-audio-video inputs and provide \\ntext-image outputs. \\nBeginning in late 2024, companies introduced what have \\nbeen termed reasoning models—models that use a chain-of-\\nthought technique in an attempt to “refine their thinking \\nprocess, try different strategies, and recognize their \\nmistakes” (e.g., OpenAI’s o1 and o3-mini models, \\nAnthropic’s Claude 3.7 Sonnet, and DeepSeek’s R1 model), \\nthough reasoning models still frequently make mistakes. \\nAlong with the development of large-scale models,'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='Generative Artificial Intelligence: Overview, Issues, and Considerations for Congress \\nhttps://crsreports.congress.gov \\ninnovations in model design and training have led to \\nimprovements in the speed and capabilities of GenAI tools. \\nConcerns and Potential Risks \\nDespite the impressive abilities of GenAI, its rapid growth \\nhas raised concerns and discussions about managing \\npotential risks. For example, the tendency of GenAI to \\nproduce incorrect or misleading results, sometimes referred \\nto as confabulation or hallucinating, might lead to the tools \\ngenerating and amplifying misinformation or being used to \\ncreate and spread disinformation. For example, in January \\n2024, researchers found that legal mistakes with LLMs \\nwere “pervasive,” and in December 2024, expert testimony \\nwas thrown out after a judge discovered fake information \\nproduced by GenAI. Because the models are generally \\ntrained on large amounts of data scraped from the internet,'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='was thrown out after a judge discovered fake information \\nproduced by GenAI. Because the models are generally \\ntrained on large amounts of data scraped from the internet, \\nthey can incorporate, reflect, and potentially amplify biases \\nin such data. OpenAI has noted that even powerful models \\nlike GPT-4 have limitations, being “not fully reliable,” and \\nthat “great care should be taken when using language model \\noutputs, particularly in high-stakes contexts.” Concerns \\nabout model inputs and limitations have led to calls for \\ngreater transparency about model training and validation. \\nSafety and security risks are ongoing concerns with GenAI \\ntools. For example, jailbreaks can trick an AI system into \\nignoring built-in safety rules. Prompt injection attacks \\ndisguise malicious inputs as non-malicious prompts, \\nmanipulating a system into such actions as leaking sensitive \\ndata. Also, depending on a company’s privacy policies, \\nU.S. user data may be stored on servers in foreign countries'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='manipulating a system into such actions as leaking sensitive \\ndata. Also, depending on a company’s privacy policies, \\nU.S. user data may be stored on servers in foreign countries \\nas has been flagged with the Chinese company DeepSeek.  \\nAs GenAI use grows, analysts have been considering how it \\nmight affect jobs and productivity. For example, will these \\ntools complement workers’ skills in existing jobs, create \\nnew jobs, or automate some jobs, displacing workers? What \\nimpact might GenAI have on economic productivity? While \\nthese have been long-standing questions for automation and \\nAI technologies, the speed, capability, and adoption of \\nGenAI has heightened labor-related concerns. \\nFederal AI Laws and GenAI Legislation \\nBills focused on AI, or including AI-focused provisions, \\nhave been enacted in prior Congresses. For example, the \\nNational Artificial Intelligence Initiative Act of 2020 \\n(Division E of P.L. 116-283) codified the establishment of a'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='have been enacted in prior Congresses. For example, the \\nNational Artificial Intelligence Initiative Act of 2020 \\n(Division E of P.L. 116-283) codified the establishment of a \\nnational AI initiative and associated federal offices and \\ncommittees. Specifically regarding GenAI, the Identifying \\nOutputs of Generative Adversarial Networks (IOGAN) Act \\n(P.L. 116-258) directed federal support of research on \\ngenerative adversarial networks. Some Members of \\nCongress have introduced bills that included GenAI, such \\nas those pertaining to the development of technical \\nstandards, deepfakes and AI-generated voice messages, and \\ntransparency and accountability of GenAI use. \\nConsiderations for Congress \\nFederal agencies and Congress have been exploring GenAI \\nuses, including for office tasks such as creating and \\nsummarizing content, writing speeches, and drafting bills. \\nAt the same time, several bills have been introduced in the \\n119th Congress regarding GenAI, building on various bills'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='summarizing content, writing speeches, and drafting bills. \\nAt the same time, several bills have been introduced in the \\n119th Congress regarding GenAI, building on various bills \\nintroduced in the 118th Congress to implement guardrails \\nfor GenAI technologies in the private sector. As GenAI \\ndevelopment continues and its use grows, Congress might \\nconsider questions and potential actions such as these \\n• Bias and ethics of use. The private and public sectors \\nmay be using federal guidance and frameworks for AI to \\naddress bias and manage risks for GenAI. Congress \\nmight consider whether additional sector-specific \\nguidance would be helpful and whether the deployment \\nof GenAI models in high-risk scenarios (e.g., mental \\nhealth therapy or generating forensic sketches) requires \\nrestrictions. \\n• Testing and transparency. Many of the biggest models \\ndeployed today are closed-source and proprietary. \\nCompanies state that they conduct internal testing and'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='restrictions. \\n• Testing and transparency. Many of the biggest models \\ndeployed today are closed-source and proprietary. \\nCompanies state that they conduct internal testing and \\nare evaluating options for external validation and \\ntesting. Congress might consider the adequacy of \\nindustry self-assessment and whether and how to \\nsupport or require independent testing and reporting of \\nresults. \\n• Economic and workforce impacts. Researchers in \\nindustry and academia have begun analyzing GenAI’s \\npotential widespread effects on labor. In November \\n2024, the National Academy of Sciences released an \\nupdated study on AI and the future of work. Congress \\nmight consider the appropriate federal role in supporting \\nU.S. workforce reskilling or upskilling in response to \\nshifting job tasks caused by the implementation of \\nGenAI. It might also consider whether and how to \\nincrease AI expertise in the government’s own \\nworkforce, such as using statutory authority to establish'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='GenAI. It might also consider whether and how to \\nincrease AI expertise in the government’s own \\nworkforce, such as using statutory authority to establish \\na federal AI scholarship-for-service program (per P.L. \\n117-167). \\n• Research and competition. Estimates have put training \\ncosts for large GenAI models in the millions to tens of \\nmillions of dollars. Some analysts have argued that cost, \\nuse of proprietary data, and access to vast computing \\npower will create a divide between those who can train \\nthe most cutting-edge LLMs (e.g., large technology \\nfirms) and those who cannot (e.g., nonprofits, start-ups, \\nuniversities). Congress might consider whether to \\nsupport access to data, training, and computing \\nresources, such as through codifying an effort like the \\nNational AI Research Resource. Further, the release of \\nadvanced, open-source models such as DeepSeek’s R1 \\nhave raised concerns about national security and \\ninternational competition. Congress might consider'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 1, 'page_label': '2', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='advanced, open-source models such as DeepSeek’s R1 \\nhave raised concerns about national security and \\ninternational competition. Congress might consider \\nwhether to support U.S. leadership in AI innovation, \\nsuch as through technical standards development and \\ncoordination with allied countries. \\n• Oversight and regulation. In considering possible \\nregulation of GenAI technologies, Congress might \\nweigh potential impacts on innovation and international \\ncompetitiveness. Do federal regulatory agencies have \\nthe authorities and resources to adequately oversee \\nGenAI tools to minimize risks and support benefits? If \\nnot, what additional authorities are needed? How might \\nfederal oversight and regulation for GenAI be distinct \\nfrom that for AI technologies more broadly? \\nLaurie Harris, Analyst in Science and Technology Policy'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='Generative Artificial Intelligence: Overview, Issues, and Considerations for Congress \\nhttps://crsreports.congress.gov | IF12426 · VERSION 5 · UPDATED \\n IF12426\\n \\n \\nDisclaimer \\nThis document was prepared by the Congressional Research Service (CRS). CRS serves as nonpartisan shared staff to \\ncongressional committees and Members of Congress. It operates solely at the behest of and under the direction of Congress. \\nInformation in a CRS Report should not be relied upon for purposes other than public understanding of information that has \\nbeen provided by CRS to Members of Congress in connection with CRS’s institutional role. CRS Reports, as a work of the \\nUnited States Government, are not subject to copyright protection in the United States. Any CRS Report may be \\nreproduced and distributed in its entirety without permission from CRS. However, as a CRS Report may include'), Document(metadata={'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2025-04-04T16:06:39-04:00', 'moddate': '2025-04-04T16:06:43-04:00', 'source': 'data\\\\pdf\\\\GenericAITest.pdf', 'total_pages': 3, 'page': 2, 'page_label': '3', 'source_file': 'GenericAITest.pdf', 'file_type': 'pdf'}, page_content='reproduced and distributed in its entirety without permission from CRS. However, as a CRS Report may include \\ncopyrighted images or material from a third party, you may need to obtain the permissio n of the copyright holder if you \\nwish to copy or otherwise use copyrighted material.')]\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e37cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding and vector db\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any , Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c82b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model : all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension : 384\n",
      "<__main__.EmbeddingManager object at 0x000001C6E54FA030>\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles document embedding generation using Sentence Transformer\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "        Args : model_name : Hugging face model for sentence embeddings\n",
    "        ll-MiniLM-L6-v2  - this model is responsible for converting text into vectors\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer Model\"\"\"    \n",
    "        try:\n",
    "            print(f\"Loading embedding model : {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension : {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while loading model {self.model_name}: {e}\") \n",
    "            raise\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "       \"\"\"Generate embeddings for a list of texts\n",
    "       Args : list of text strings to embed\n",
    "       Returns :\n",
    "       numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "       \"\"\"\n",
    "       if not self.model:\n",
    "           raise ValueError(\"Model not loaded\")\n",
    "       \n",
    "       print (f\"Generating embeddings for {len(texts)} texts\")\n",
    "       embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "       print(f\"Generated embeddings with shape : {embeddings.shape}\")\n",
    "       return embeddings\n",
    "    \n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "print(embedding_manager)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8ac1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: all_pdf_documents\n",
      "Existing docuemnts in collection : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1c6e6b0a570>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "### Vector Store\n",
    "class VectorStore:\n",
    "    \"\"\"Manges document embeddings in a ChromaDB vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"all_pdf_documents\", persist_directory: str = \"data\\\\vector_store\"):\n",
    "        \"\"\"Initialzie the vector store\n",
    "        Args: \n",
    "        collection_name: Name of the ChromaDB collection\n",
    "        persist_directory: Directory to persist the vector store\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initilize ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            # create persistent ChromaDB Client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"description\" : \"PDF document embeddings for RAG\"}\n",
    "            )    \n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing docuemnts in collection : {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vecotr store : {e}\")\n",
    "            raise    \n",
    "\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"       \n",
    "            Add documents and their embeddings to the vectore store.\n",
    "            Args : List of Langchain documents\n",
    "            embeddings : Corresponding embeddings for the documents. \n",
    "        \"\"\"\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} docuemnts to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embedding_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id=f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #Document Content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #Embedding\n",
    "            embedding_list.append(embedding.tolist())\n",
    "            \n",
    "\n",
    "            # Add to collection\n",
    "            try:\n",
    "                self.collection.add(\n",
    "                    ids=ids,\n",
    "                    embeddings=embedding_list,\n",
    "                    metadatas=metadatas,\n",
    "                    documents=documents_text\n",
    "                )\n",
    "                print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "                print(f\"Total docuemnts in collection : {self.collection.count}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding documents to vector store: {e}\")    \n",
    "                raise\n",
    "\n",
    "vectorStore = VectorStore()\n",
    "vectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3244400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 17 texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af13ab49d2bc4b71a8b7f6d921a039ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape : (17, 384)\n",
      "Adding 17 docuemnts to vector store...\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n",
      "Successfully added 17 documents to vector store\n",
      "Total docuemnts in collection : <bound method Collection.count of Collection(name=all_pdf_documents)>\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## Generte the embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "\n",
    "# Store in the vector database\n",
    "vectorStore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorStore,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319b0aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RAGRetriever object at 0x000001C6E8730C50>\n"
     ]
    }
   ],
   "source": [
    "print(rag_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a68950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is Generative Artificail intelligence refer ?'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e97cafc4e6411887c729294f91381d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape : (1, 384)\n",
      "Retrieved 1 documents (after filtering)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_1ae960f8_0',\n",
       "  'content': 'https://crsreports.congress.gov \\n \\nUpdated April 2, 2025\\nGenerative Artificial Intelligence: Overview, Issues, and \\nConsiderations for Congress \\nGenerative artificial intelligence (GenAI) refers to AI \\nmodels, in particular those that use machine learning (ML) \\nand are trained on large volumes of data, that are able to \\ngenerate new content. In contrast, other AI models may \\nhave a primary goal of classifying data, such as facial \\nrecognition image data, or making decisions, such as those \\nused in automated vehicles. GenAI, when prompted (often \\nby a user inputting text), can create various outputs, \\nincluding text, images, videos, computer code, or music. \\nThe public release of many GenAI tools, and the race by \\ncompanies to develop ever-more powerful AI models, have \\ngenerated widespread discussion of their capabilities, \\npotential concerns with their use, and debates about their \\ngovernance and regulation. This CRS In Focus describes',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'creationdate': '2025-04-04T16:06:39-04:00',\n",
       "   'moddate': '2025-04-04T16:06:43-04:00',\n",
       "   'total_pages': 3,\n",
       "   'source_file': 'GenericAITest.pdf',\n",
       "   'page_label': '1',\n",
       "   'source': 'data\\\\pdf\\\\GenericAITest.pdf',\n",
       "   'content_length': 950,\n",
       "   'producer': 'iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version); modified using iText® 7.1.2 ©2000-2018 iText Group NV (AGPL-version)',\n",
       "   'page': 0,\n",
       "   'creator': 'PyPDF',\n",
       "   'doc_index': 0},\n",
       "  'similarity_score': 0.10424667596817017,\n",
       "  'distance': 0.8957533240318298,\n",
       "  'rank': 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"what is Generative Artificail intelligence refer ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_retriever.retrieve(\"What are the capabilities of AI ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
